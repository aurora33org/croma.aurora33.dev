{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 58, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/config.ts"],"sourcesContent":["export const config = {\n  server: {\n    port: parseInt(process.env.PORT || '3000', 10),\n    nodeEnv: process.env.NODE_ENV || 'development'\n  },\n\n  // Upload limits\n  upload: {\n    maxFileSize: parseInt(process.env.MAX_FILE_SIZE || '10485760', 10), // 10MB\n    maxFiles: parseInt(process.env.MAX_FILES || '20', 10),\n    allowedMimeTypes: ['image/jpeg', 'image/jpg', 'image/png', 'image/webp']\n  },\n\n  // Cleanup configuration\n  cleanup: {\n    interval: parseInt(process.env.CLEANUP_INTERVAL || '15', 10), // minutes\n    fileTTL: parseInt(process.env.FILE_TTL || '3600', 10) // seconds (1 hour)\n  },\n\n  // Listmonk (optional)\n  listmonk: {\n    enabled: process.env.LISTMONK_ENABLED === 'true',\n    url: process.env.LISTMONK_URL || '',\n    apiKey: process.env.LISTMONK_API_KEY || '',\n    listId: process.env.LISTMONK_LIST_ID || ''\n  },\n\n  // Storage\n  storage: {\n    baseDir: '/tmp/jobs'\n  },\n\n  // Supported formats\n  supportedFormats: ['jpeg', 'jpg', 'png', 'webp', 'gif'],\n  outputFormats: ['webp', 'jpeg', 'png']\n};\n"],"names":[],"mappings":";;;;AAAO,MAAM,SAAS;IACpB,QAAQ;QACN,MAAM,SAAS,QAAQ,GAAG,CAAC,IAAI,IAAI,QAAQ;QAC3C,SAAS,mDAAwB;IACnC;IAEA,gBAAgB;IAChB,QAAQ;QACN,aAAa,SAAS,QAAQ,GAAG,CAAC,aAAa,IAAI,YAAY;QAC/D,UAAU,SAAS,QAAQ,GAAG,CAAC,SAAS,IAAI,MAAM;QAClD,kBAAkB;YAAC;YAAc;YAAa;YAAa;SAAa;IAC1E;IAEA,wBAAwB;IACxB,SAAS;QACP,UAAU,SAAS,QAAQ,GAAG,CAAC,gBAAgB,IAAI,MAAM;QACzD,SAAS,SAAS,QAAQ,GAAG,CAAC,QAAQ,IAAI,QAAQ,IAAI,mBAAmB;IAC3E;IAEA,sBAAsB;IACtB,UAAU;QACR,SAAS,QAAQ,GAAG,CAAC,gBAAgB,KAAK;QAC1C,KAAK,QAAQ,GAAG,CAAC,YAAY,IAAI;QACjC,QAAQ,QAAQ,GAAG,CAAC,gBAAgB,IAAI;QACxC,QAAQ,QAAQ,GAAG,CAAC,gBAAgB,IAAI;IAC1C;IAEA,UAAU;IACV,SAAS;QACP,SAAS;IACX;IAEA,oBAAoB;IACpB,kBAAkB;QAAC;QAAQ;QAAO;QAAO;QAAQ;KAAM;IACvD,eAAe;QAAC;QAAQ;QAAQ;KAAM;AACxC"}},
    {"offset": {"line": 112, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/utils/logger.ts"],"sourcesContent":["import { config } from '../config';\n\nconst colors = {\n  reset: '\\x1b[0m',\n  bright: '\\x1b[1m',\n  red: '\\x1b[31m',\n  green: '\\x1b[32m',\n  yellow: '\\x1b[33m',\n  blue: '\\x1b[34m',\n  magenta: '\\x1b[35m',\n  cyan: '\\x1b[36m'\n};\n\nconst getTimestamp = () => {\n  return new Date().toISOString();\n};\n\nexport const logger = {\n  info: (message: string, ...args: any[]) => {\n    console.log(\n      `${colors.cyan}[INFO]${colors.reset} ${colors.bright}${getTimestamp()}${colors.reset} - ${message}`,\n      ...args\n    );\n  },\n\n  success: (message: string, ...args: any[]) => {\n    console.log(\n      `${colors.green}[SUCCESS]${colors.reset} ${colors.bright}${getTimestamp()}${colors.reset} - ${message}`,\n      ...args\n    );\n  },\n\n  warn: (message: string, ...args: any[]) => {\n    console.warn(\n      `${colors.yellow}[WARN]${colors.reset} ${colors.bright}${getTimestamp()}${colors.reset} - ${message}`,\n      ...args\n    );\n  },\n\n  error: (message: string, ...args: any[]) => {\n    console.error(\n      `${colors.red}[ERROR]${colors.reset} ${colors.bright}${getTimestamp()}${colors.reset} - ${message}`,\n      ...args\n    );\n  },\n\n  debug: (message: string, ...args: any[]) => {\n    if (config.server.nodeEnv === 'development') {\n      console.log(\n        `${colors.magenta}[DEBUG]${colors.reset} ${colors.bright}${getTimestamp()}${colors.reset} - ${message}`,\n        ...args\n      );\n    }\n  }\n};\n"],"names":[],"mappings":";;;;AAAA;;AAEA,MAAM,SAAS;IACb,OAAO;IACP,QAAQ;IACR,KAAK;IACL,OAAO;IACP,QAAQ;IACR,MAAM;IACN,SAAS;IACT,MAAM;AACR;AAEA,MAAM,eAAe;IACnB,OAAO,IAAI,OAAO,WAAW;AAC/B;AAEO,MAAM,SAAS;IACpB,MAAM,CAAC,SAAiB,GAAG;QACzB,QAAQ,GAAG,CACT,GAAG,OAAO,IAAI,CAAC,MAAM,EAAE,OAAO,KAAK,CAAC,CAAC,EAAE,OAAO,MAAM,GAAG,iBAAiB,OAAO,KAAK,CAAC,GAAG,EAAE,SAAS,KAChG;IAEP;IAEA,SAAS,CAAC,SAAiB,GAAG;QAC5B,QAAQ,GAAG,CACT,GAAG,OAAO,KAAK,CAAC,SAAS,EAAE,OAAO,KAAK,CAAC,CAAC,EAAE,OAAO,MAAM,GAAG,iBAAiB,OAAO,KAAK,CAAC,GAAG,EAAE,SAAS,KACpG;IAEP;IAEA,MAAM,CAAC,SAAiB,GAAG;QACzB,QAAQ,IAAI,CACV,GAAG,OAAO,MAAM,CAAC,MAAM,EAAE,OAAO,KAAK,CAAC,CAAC,EAAE,OAAO,MAAM,GAAG,iBAAiB,OAAO,KAAK,CAAC,GAAG,EAAE,SAAS,KAClG;IAEP;IAEA,OAAO,CAAC,SAAiB,GAAG;QAC1B,QAAQ,KAAK,CACX,GAAG,OAAO,GAAG,CAAC,OAAO,EAAE,OAAO,KAAK,CAAC,CAAC,EAAE,OAAO,MAAM,GAAG,iBAAiB,OAAO,KAAK,CAAC,GAAG,EAAE,SAAS,KAChG;IAEP;IAEA,OAAO,CAAC,SAAiB,GAAG;QAC1B,IAAI,yHAAM,CAAC,MAAM,CAAC,OAAO,KAAK,eAAe;YAC3C,QAAQ,GAAG,CACT,GAAG,OAAO,OAAO,CAAC,OAAO,EAAE,OAAO,KAAK,CAAC,CAAC,EAAE,OAAO,MAAM,GAAG,iBAAiB,OAAO,KAAK,CAAC,GAAG,EAAE,SAAS,KACpG;QAEP;IACF;AACF"}},
    {"offset": {"line": 154, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/job-manager.ts"],"sourcesContent":["import { v4 as uuidv4 } from 'uuid';\nimport { logger } from '../utils/logger';\n\ninterface JobFile {\n  filename: string;\n  size: number;\n}\n\ninterface ProcessedFile {\n  filename: string;\n  originalSize: number;\n  compressedSize: number;\n  reduction: number;\n}\n\ninterface Job {\n  id: string;\n  status: 'created' | 'uploading' | 'uploaded' | 'processing' | 'completed' | 'failed';\n  uploadedFiles: JobFile[];\n  processedFiles: ProcessedFile[];\n  settings: any;\n  progress: number;\n  totalFiles: number;\n  processedCount: number;\n  originalSize: number;\n  compressedSize: number;\n  error: string | null;\n  createdAt: number;\n  updatedAt: number;\n}\n\nclass JobManager {\n  private jobs: Map<string, Job> = new Map();\n\n  createJob(): Job {\n    const jobId = uuidv4();\n    const job: Job = {\n      id: jobId,\n      status: 'created',\n      uploadedFiles: [],\n      processedFiles: [],\n      settings: null,\n      progress: 0,\n      totalFiles: 0,\n      processedCount: 0,\n      originalSize: 0,\n      compressedSize: 0,\n      error: null,\n      createdAt: Date.now(),\n      updatedAt: Date.now()\n    };\n\n    this.jobs.set(jobId, job);\n    logger.info(`Created new job: ${jobId}`);\n    return job;\n  }\n\n  getJob(jobId: string): Job | undefined {\n    return this.jobs.get(jobId);\n  }\n\n  updateJob(jobId: string, updates: Partial<Job>): Job | null {\n    const job = this.jobs.get(jobId);\n    if (!job) {\n      logger.warn(`Attempted to update non-existent job: ${jobId}`);\n      return null;\n    }\n\n    Object.assign(job, updates, { updatedAt: Date.now() });\n    this.jobs.set(jobId, job);\n    logger.debug(`Updated job ${jobId}:`, updates);\n    return job;\n  }\n\n  updateProgress(jobId: string, processedCount: number, totalFiles: number): Job | null {\n    const progress = Math.round((processedCount / totalFiles) * 100);\n    return this.updateJob(jobId, {\n      processedCount,\n      progress,\n      status: progress === 100 ? 'completed' : 'processing'\n    });\n  }\n\n  addUploadedFile(jobId: string, filename: string, size: number): Job | null {\n    const job = this.jobs.get(jobId);\n    if (!job) return null;\n\n    job.uploadedFiles.push({ filename, size });\n    job.totalFiles = job.uploadedFiles.length;\n    job.originalSize += size;\n    job.updatedAt = Date.now();\n\n    this.jobs.set(jobId, job);\n    return job;\n  }\n\n  addProcessedFile(jobId: string, filename: string, originalSize: number, compressedSize: number): Job | null {\n    const job = this.jobs.get(jobId);\n    if (!job) return null;\n\n    job.processedFiles.push({\n      filename,\n      originalSize,\n      compressedSize,\n      reduction: Math.round(((originalSize - compressedSize) / originalSize) * 100)\n    });\n    job.compressedSize += compressedSize;\n    job.updatedAt = Date.now();\n\n    this.jobs.set(jobId, job);\n    return job;\n  }\n\n  setJobSettings(jobId: string, settings: any): Job | null {\n    return this.updateJob(jobId, { settings });\n  }\n\n  setJobStatus(jobId: string, status: Job['status'], error: string | null = null): Job | null {\n    return this.updateJob(jobId, { status, error });\n  }\n\n  deleteJob(jobId: string): boolean {\n    const deleted = this.jobs.delete(jobId);\n    if (deleted) {\n      logger.info(`Deleted job from memory: ${jobId}`);\n    }\n    return deleted;\n  }\n\n  getAllJobs(): Job[] {\n    return Array.from(this.jobs.values());\n  }\n\n  getJobStats(jobId: string) {\n    const job = this.jobs.get(jobId);\n    if (!job) return null;\n\n    return {\n      id: job.id,\n      status: job.status,\n      progress: job.progress,\n      totalFiles: job.totalFiles,\n      processedCount: job.processedCount,\n      originalSize: job.originalSize,\n      compressedSize: job.compressedSize,\n      reduction: job.originalSize > 0\n        ? Math.round(((job.originalSize - job.compressedSize) / job.originalSize) * 100)\n        : 0,\n      createdAt: job.createdAt,\n      error: job.error\n    };\n  }\n}\n\n// Global singleton to persist across hot reloads in development\ndeclare global {\n  var jobManagerInstance: JobManager | undefined;\n}\n\nexport const jobManager = global.jobManagerInstance || new JobManager();\n\n// Store reference globally to prevent recreation on hot reload\nif (process.env.NODE_ENV === 'development') {\n  global.jobManagerInstance = jobManager;\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AA8BA,MAAM;IACI,OAAyB,IAAI,MAAM;IAE3C,YAAiB;QACf,MAAM,QAAQ,IAAA,mLAAM;QACpB,MAAM,MAAW;YACf,IAAI;YACJ,QAAQ;YACR,eAAe,EAAE;YACjB,gBAAgB,EAAE;YAClB,UAAU;YACV,UAAU;YACV,YAAY;YACZ,gBAAgB;YAChB,cAAc;YACd,gBAAgB;YAChB,OAAO;YACP,WAAW,KAAK,GAAG;YACnB,WAAW,KAAK,GAAG;QACrB;QAEA,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO;QACrB,kIAAM,CAAC,IAAI,CAAC,CAAC,iBAAiB,EAAE,OAAO;QACvC,OAAO;IACT;IAEA,OAAO,KAAa,EAAmB;QACrC,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;IACvB;IAEA,UAAU,KAAa,EAAE,OAAqB,EAAc;QAC1D,MAAM,MAAM,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;QAC1B,IAAI,CAAC,KAAK;YACR,kIAAM,CAAC,IAAI,CAAC,CAAC,sCAAsC,EAAE,OAAO;YAC5D,OAAO;QACT;QAEA,OAAO,MAAM,CAAC,KAAK,SAAS;YAAE,WAAW,KAAK,GAAG;QAAG;QACpD,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO;QACrB,kIAAM,CAAC,KAAK,CAAC,CAAC,YAAY,EAAE,MAAM,CAAC,CAAC,EAAE;QACtC,OAAO;IACT;IAEA,eAAe,KAAa,EAAE,cAAsB,EAAE,UAAkB,EAAc;QACpF,MAAM,WAAW,KAAK,KAAK,CAAC,AAAC,iBAAiB,aAAc;QAC5D,OAAO,IAAI,CAAC,SAAS,CAAC,OAAO;YAC3B;YACA;YACA,QAAQ,aAAa,MAAM,cAAc;QAC3C;IACF;IAEA,gBAAgB,KAAa,EAAE,QAAgB,EAAE,IAAY,EAAc;QACzE,MAAM,MAAM,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;QAC1B,IAAI,CAAC,KAAK,OAAO;QAEjB,IAAI,aAAa,CAAC,IAAI,CAAC;YAAE;YAAU;QAAK;QACxC,IAAI,UAAU,GAAG,IAAI,aAAa,CAAC,MAAM;QACzC,IAAI,YAAY,IAAI;QACpB,IAAI,SAAS,GAAG,KAAK,GAAG;QAExB,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO;QACrB,OAAO;IACT;IAEA,iBAAiB,KAAa,EAAE,QAAgB,EAAE,YAAoB,EAAE,cAAsB,EAAc;QAC1G,MAAM,MAAM,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;QAC1B,IAAI,CAAC,KAAK,OAAO;QAEjB,IAAI,cAAc,CAAC,IAAI,CAAC;YACtB;YACA;YACA;YACA,WAAW,KAAK,KAAK,CAAC,AAAC,CAAC,eAAe,cAAc,IAAI,eAAgB;QAC3E;QACA,IAAI,cAAc,IAAI;QACtB,IAAI,SAAS,GAAG,KAAK,GAAG;QAExB,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,OAAO;QACrB,OAAO;IACT;IAEA,eAAe,KAAa,EAAE,QAAa,EAAc;QACvD,OAAO,IAAI,CAAC,SAAS,CAAC,OAAO;YAAE;QAAS;IAC1C;IAEA,aAAa,KAAa,EAAE,MAAqB,EAAE,QAAuB,IAAI,EAAc;QAC1F,OAAO,IAAI,CAAC,SAAS,CAAC,OAAO;YAAE;YAAQ;QAAM;IAC/C;IAEA,UAAU,KAAa,EAAW;QAChC,MAAM,UAAU,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC;QACjC,IAAI,SAAS;YACX,kIAAM,CAAC,IAAI,CAAC,CAAC,yBAAyB,EAAE,OAAO;QACjD;QACA,OAAO;IACT;IAEA,aAAoB;QAClB,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM;IACpC;IAEA,YAAY,KAAa,EAAE;QACzB,MAAM,MAAM,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC;QAC1B,IAAI,CAAC,KAAK,OAAO;QAEjB,OAAO;YACL,IAAI,IAAI,EAAE;YACV,QAAQ,IAAI,MAAM;YAClB,UAAU,IAAI,QAAQ;YACtB,YAAY,IAAI,UAAU;YAC1B,gBAAgB,IAAI,cAAc;YAClC,cAAc,IAAI,YAAY;YAC9B,gBAAgB,IAAI,cAAc;YAClC,WAAW,IAAI,YAAY,GAAG,IAC1B,KAAK,KAAK,CAAC,AAAC,CAAC,IAAI,YAAY,GAAG,IAAI,cAAc,IAAI,IAAI,YAAY,GAAI,OAC1E;YACJ,WAAW,IAAI,SAAS;YACxB,OAAO,IAAI,KAAK;QAClB;IACF;AACF;AAOO,MAAM,aAAa,OAAO,kBAAkB,IAAI,IAAI;AAE3D,+DAA+D;AAC/D,wCAA4C;IAC1C,OAAO,kBAAkB,GAAG;AAC9B"}},
    {"offset": {"line": 289, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/storage-service.ts"],"sourcesContent":["import { promises as fs } from 'fs';\nimport path from 'path';\nimport { config } from '../config';\nimport { logger } from '../utils/logger';\n\nclass StorageService {\n  private baseDir: string = config.storage.baseDir;\n\n  async initialize() {\n    try {\n      await fs.mkdir(this.baseDir, { recursive: true });\n      logger.info(`Storage initialized at ${this.baseDir}`);\n    } catch (error: any) {\n      logger.error('Failed to initialize storage:', error);\n      throw error;\n    }\n  }\n\n  getJobDir(jobId: string): string {\n    return path.join(this.baseDir, jobId);\n  }\n\n  getUploadDir(jobId: string): string {\n    return path.join(this.getJobDir(jobId), 'uploads');\n  }\n\n  getProcessedDir(jobId: string): string {\n    return path.join(this.getJobDir(jobId), 'processed');\n  }\n\n  async createJobDirectories(jobId: string) {\n    try {\n      const uploadDir = this.getUploadDir(jobId);\n      const processedDir = this.getProcessedDir(jobId);\n\n      await fs.mkdir(uploadDir, { recursive: true });\n      await fs.mkdir(processedDir, { recursive: true });\n\n      logger.debug(`Created directories for job ${jobId}`);\n      return { uploadDir, processedDir };\n    } catch (error: any) {\n      logger.error(`Failed to create directories for job ${jobId}:`, error);\n      throw error;\n    }\n  }\n\n  async saveMetadata(jobId: string, metadata: any) {\n    try {\n      const metadataPath = path.join(this.getJobDir(jobId), 'metadata.json');\n      await fs.writeFile(metadataPath, JSON.stringify(metadata, null, 2));\n      logger.debug(`Saved metadata for job ${jobId}`);\n    } catch (error: any) {\n      logger.error(`Failed to save metadata for job ${jobId}:`, error);\n      throw error;\n    }\n  }\n\n  async getMetadata(jobId: string) {\n    try {\n      const metadataPath = path.join(this.getJobDir(jobId), 'metadata.json');\n      const data = await fs.readFile(metadataPath, 'utf-8');\n      return JSON.parse(data);\n    } catch (error: any) {\n      logger.error(`Failed to read metadata for job ${jobId}:`, error);\n      return null;\n    }\n  }\n\n  async listFiles(directory: string): Promise<string[]> {\n    try {\n      const files = await fs.readdir(directory);\n      return files.filter(file => !file.startsWith('.'));\n    } catch (error: any) {\n      logger.error(`Failed to list files in ${directory}:`, error);\n      return [];\n    }\n  }\n\n  async getFileStats(filePath: string) {\n    try {\n      const stats = await fs.stat(filePath);\n      return {\n        size: stats.size,\n        created: stats.birthtime,\n        modified: stats.mtime\n      };\n    } catch (error: any) {\n      logger.error(`Failed to get stats for ${filePath}:`, error);\n      return null;\n    }\n  }\n\n  async deleteJob(jobId: string): Promise<boolean> {\n    try {\n      const jobDir = this.getJobDir(jobId);\n      await fs.rm(jobDir, { recursive: true, force: true });\n      logger.info(`Deleted job directory: ${jobId}`);\n      return true;\n    } catch (error: any) {\n      logger.error(`Failed to delete job ${jobId}:`, error);\n      return false;\n    }\n  }\n\n  async cleanupOldJobs(maxAge: number): Promise<number> {\n    try {\n      const jobs = await fs.readdir(this.baseDir);\n      const now = Date.now();\n      let cleaned = 0;\n\n      for (const jobId of jobs) {\n        const jobDir = this.getJobDir(jobId);\n        const metadataPath = path.join(jobDir, 'metadata.json');\n\n        try {\n          const stats = await fs.stat(metadataPath);\n          const age = (now - stats.mtime.getTime()) / 1000; // seconds\n\n          if (age > maxAge) {\n            await this.deleteJob(jobId);\n            cleaned++;\n          }\n        } catch (error) {\n          // If metadata doesn't exist, delete the job anyway\n          await this.deleteJob(jobId);\n          cleaned++;\n        }\n      }\n\n      if (cleaned > 0) {\n        logger.info(`Cleanup completed: removed ${cleaned} old job(s)`);\n      }\n\n      return cleaned;\n    } catch (error: any) {\n      logger.error('Failed to cleanup old jobs:', error);\n      return 0;\n    }\n  }\n}\n\n// Global singleton to persist across hot reloads in development\ndeclare global {\n  var storageServiceInstance: StorageService | undefined;\n}\n\nexport const storageService = global.storageServiceInstance || new StorageService();\n\n// Store reference globally to prevent recreation on hot reload\nif (process.env.NODE_ENV === 'development') {\n  global.storageServiceInstance = storageService;\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAEA,MAAM;IACI,UAAkB,yHAAM,CAAC,OAAO,CAAC,OAAO,CAAC;IAEjD,MAAM,aAAa;QACjB,IAAI;YACF,MAAM,yGAAE,CAAC,KAAK,CAAC,IAAI,CAAC,OAAO,EAAE;gBAAE,WAAW;YAAK;YAC/C,kIAAM,CAAC,IAAI,CAAC,CAAC,uBAAuB,EAAE,IAAI,CAAC,OAAO,EAAE;QACtD,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,iCAAiC;YAC9C,MAAM;QACR;IACF;IAEA,UAAU,KAAa,EAAU;QAC/B,OAAO,4GAAI,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE;IACjC;IAEA,aAAa,KAAa,EAAU;QAClC,OAAO,4GAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,QAAQ;IAC1C;IAEA,gBAAgB,KAAa,EAAU;QACrC,OAAO,4GAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,QAAQ;IAC1C;IAEA,MAAM,qBAAqB,KAAa,EAAE;QACxC,IAAI;YACF,MAAM,YAAY,IAAI,CAAC,YAAY,CAAC;YACpC,MAAM,eAAe,IAAI,CAAC,eAAe,CAAC;YAE1C,MAAM,yGAAE,CAAC,KAAK,CAAC,WAAW;gBAAE,WAAW;YAAK;YAC5C,MAAM,yGAAE,CAAC,KAAK,CAAC,cAAc;gBAAE,WAAW;YAAK;YAE/C,kIAAM,CAAC,KAAK,CAAC,CAAC,4BAA4B,EAAE,OAAO;YACnD,OAAO;gBAAE;gBAAW;YAAa;QACnC,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,qCAAqC,EAAE,MAAM,CAAC,CAAC,EAAE;YAC/D,MAAM;QACR;IACF;IAEA,MAAM,aAAa,KAAa,EAAE,QAAa,EAAE;QAC/C,IAAI;YACF,MAAM,eAAe,4GAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,QAAQ;YACtD,MAAM,yGAAE,CAAC,SAAS,CAAC,cAAc,KAAK,SAAS,CAAC,UAAU,MAAM;YAChE,kIAAM,CAAC,KAAK,CAAC,CAAC,uBAAuB,EAAE,OAAO;QAChD,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,gCAAgC,EAAE,MAAM,CAAC,CAAC,EAAE;YAC1D,MAAM;QACR;IACF;IAEA,MAAM,YAAY,KAAa,EAAE;QAC/B,IAAI;YACF,MAAM,eAAe,4GAAI,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,QAAQ;YACtD,MAAM,OAAO,MAAM,yGAAE,CAAC,QAAQ,CAAC,cAAc;YAC7C,OAAO,KAAK,KAAK,CAAC;QACpB,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,gCAAgC,EAAE,MAAM,CAAC,CAAC,EAAE;YAC1D,OAAO;QACT;IACF;IAEA,MAAM,UAAU,SAAiB,EAAqB;QACpD,IAAI;YACF,MAAM,QAAQ,MAAM,yGAAE,CAAC,OAAO,CAAC;YAC/B,OAAO,MAAM,MAAM,CAAC,CAAA,OAAQ,CAAC,KAAK,UAAU,CAAC;QAC/C,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,wBAAwB,EAAE,UAAU,CAAC,CAAC,EAAE;YACtD,OAAO,EAAE;QACX;IACF;IAEA,MAAM,aAAa,QAAgB,EAAE;QACnC,IAAI;YACF,MAAM,QAAQ,MAAM,yGAAE,CAAC,IAAI,CAAC;YAC5B,OAAO;gBACL,MAAM,MAAM,IAAI;gBAChB,SAAS,MAAM,SAAS;gBACxB,UAAU,MAAM,KAAK;YACvB;QACF,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,wBAAwB,EAAE,SAAS,CAAC,CAAC,EAAE;YACrD,OAAO;QACT;IACF;IAEA,MAAM,UAAU,KAAa,EAAoB;QAC/C,IAAI;YACF,MAAM,SAAS,IAAI,CAAC,SAAS,CAAC;YAC9B,MAAM,yGAAE,CAAC,EAAE,CAAC,QAAQ;gBAAE,WAAW;gBAAM,OAAO;YAAK;YACnD,kIAAM,CAAC,IAAI,CAAC,CAAC,uBAAuB,EAAE,OAAO;YAC7C,OAAO;QACT,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,qBAAqB,EAAE,MAAM,CAAC,CAAC,EAAE;YAC/C,OAAO;QACT;IACF;IAEA,MAAM,eAAe,MAAc,EAAmB;QACpD,IAAI;YACF,MAAM,OAAO,MAAM,yGAAE,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO;YAC1C,MAAM,MAAM,KAAK,GAAG;YACpB,IAAI,UAAU;YAEd,KAAK,MAAM,SAAS,KAAM;gBACxB,MAAM,SAAS,IAAI,CAAC,SAAS,CAAC;gBAC9B,MAAM,eAAe,4GAAI,CAAC,IAAI,CAAC,QAAQ;gBAEvC,IAAI;oBACF,MAAM,QAAQ,MAAM,yGAAE,CAAC,IAAI,CAAC;oBAC5B,MAAM,MAAM,CAAC,MAAM,MAAM,KAAK,CAAC,OAAO,EAAE,IAAI,MAAM,UAAU;oBAE5D,IAAI,MAAM,QAAQ;wBAChB,MAAM,IAAI,CAAC,SAAS,CAAC;wBACrB;oBACF;gBACF,EAAE,OAAO,OAAO;oBACd,mDAAmD;oBACnD,MAAM,IAAI,CAAC,SAAS,CAAC;oBACrB;gBACF;YACF;YAEA,IAAI,UAAU,GAAG;gBACf,kIAAM,CAAC,IAAI,CAAC,CAAC,2BAA2B,EAAE,QAAQ,WAAW,CAAC;YAChE;YAEA,OAAO;QACT,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,+BAA+B;YAC5C,OAAO;QACT;IACF;AACF;AAOO,MAAM,iBAAiB,OAAO,sBAAsB,IAAI,IAAI;AAEnE,+DAA+D;AAC/D,wCAA4C;IAC1C,OAAO,sBAAsB,GAAG;AAClC"}},
    {"offset": {"line": 451, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/cleanup-service.ts"],"sourcesContent":["import cron, { ScheduledTask } from 'node-cron';\nimport { config } from '../config';\nimport { storageService } from './storage-service';\nimport { jobManager } from './job-manager';\nimport { logger } from '../utils/logger';\n\nclass CleanupService {\n  private task: ScheduledTask | null = null;\n  private isRunning = false;\n\n  start() {\n    if (this.task) {\n      logger.warn('Cleanup service is already running');\n      return;\n    }\n\n    // Run every N minutes based on config\n    const cronExpression = `*/${config.cleanup.interval} * * * *`;\n\n    this.task = cron.schedule(cronExpression, async () => {\n      await this.cleanup();\n    });\n\n    logger.info(`Cleanup service started (runs every ${config.cleanup.interval} minutes)`);\n\n    // Run initial cleanup after 1 minute\n    setTimeout(() => this.cleanup(), 60000);\n  }\n\n  async cleanup() {\n    if (this.isRunning) {\n      logger.debug('Cleanup already in progress, skipping...');\n      return;\n    }\n\n    this.isRunning = true;\n    logger.info('Starting cleanup...');\n\n    try {\n      // Clean up old job files\n      const cleaned = await storageService.cleanupOldJobs(config.cleanup.fileTTL);\n\n      // Clean up old jobs from memory\n      const jobs = jobManager.getAllJobs();\n      const now = Date.now();\n      let memoryCleanedCount = 0;\n\n      for (const job of jobs) {\n        const age = (now - job.updatedAt) / 1000; // seconds\n        if (age > config.cleanup.fileTTL) {\n          jobManager.deleteJob(job.id);\n          memoryCleanedCount++;\n        }\n      }\n\n      if (memoryCleanedCount > 0) {\n        logger.info(`Removed ${memoryCleanedCount} old job(s) from memory`);\n      }\n\n      if (cleaned > 0 || memoryCleanedCount > 0) {\n        logger.success(`Cleanup completed: ${cleaned} file jobs, ${memoryCleanedCount} memory jobs`);\n      } else {\n        logger.debug('Cleanup completed: nothing to clean');\n      }\n    } catch (error) {\n      logger.error('Cleanup failed:', error);\n    } finally {\n      this.isRunning = false;\n    }\n  }\n\n  stop() {\n    if (this.task) {\n      this.task.stop();\n      this.task = null;\n      logger.info('Cleanup service stopped');\n    }\n  }\n\n  async runNow() {\n    return this.cleanup();\n  }\n}\n\n// Global singleton to persist across hot reloads in development\ndeclare global {\n  var cleanupServiceInstance: CleanupService | undefined;\n}\n\nexport const cleanupService = global.cleanupServiceInstance || new CleanupService();\n\n// Store reference globally to prevent recreation on hot reload\nif (process.env.NODE_ENV === 'development') {\n  global.cleanupServiceInstance = cleanupService;\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;;;;;;;;;;AAEA,MAAM;IACI,OAA6B,KAAK;IAClC,YAAY,MAAM;IAE1B,QAAQ;QACN,IAAI,IAAI,CAAC,IAAI,EAAE;YACb,kIAAM,CAAC,IAAI,CAAC;YACZ;QACF;QAEA,sCAAsC;QACtC,MAAM,iBAAiB,CAAC,EAAE,EAAE,yHAAM,CAAC,OAAO,CAAC,QAAQ,CAAC,QAAQ,CAAC;QAE7D,IAAI,CAAC,IAAI,GAAG,mIAAI,CAAC,QAAQ,CAAC,gBAAgB;YACxC,MAAM,IAAI,CAAC,OAAO;QACpB;QAEA,kIAAM,CAAC,IAAI,CAAC,CAAC,oCAAoC,EAAE,yHAAM,CAAC,OAAO,CAAC,QAAQ,CAAC,SAAS,CAAC;QAErF,qCAAqC;QACrC,WAAW,IAAM,IAAI,CAAC,OAAO,IAAI;IACnC;IAEA,MAAM,UAAU;QACd,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,kIAAM,CAAC,KAAK,CAAC;YACb;QACF;QAEA,IAAI,CAAC,SAAS,GAAG;QACjB,kIAAM,CAAC,IAAI,CAAC;QAEZ,IAAI;YACF,yBAAyB;YACzB,MAAM,UAAU,MAAM,yJAAc,CAAC,cAAc,CAAC,yHAAM,CAAC,OAAO,CAAC,OAAO;YAE1E,gCAAgC;YAChC,MAAM,OAAO,iJAAU,CAAC,UAAU;YAClC,MAAM,MAAM,KAAK,GAAG;YACpB,IAAI,qBAAqB;YAEzB,KAAK,MAAM,OAAO,KAAM;gBACtB,MAAM,MAAM,CAAC,MAAM,IAAI,SAAS,IAAI,MAAM,UAAU;gBACpD,IAAI,MAAM,yHAAM,CAAC,OAAO,CAAC,OAAO,EAAE;oBAChC,iJAAU,CAAC,SAAS,CAAC,IAAI,EAAE;oBAC3B;gBACF;YACF;YAEA,IAAI,qBAAqB,GAAG;gBAC1B,kIAAM,CAAC,IAAI,CAAC,CAAC,QAAQ,EAAE,mBAAmB,uBAAuB,CAAC;YACpE;YAEA,IAAI,UAAU,KAAK,qBAAqB,GAAG;gBACzC,kIAAM,CAAC,OAAO,CAAC,CAAC,mBAAmB,EAAE,QAAQ,YAAY,EAAE,mBAAmB,YAAY,CAAC;YAC7F,OAAO;gBACL,kIAAM,CAAC,KAAK,CAAC;YACf;QACF,EAAE,OAAO,OAAO;YACd,kIAAM,CAAC,KAAK,CAAC,mBAAmB;QAClC,SAAU;YACR,IAAI,CAAC,SAAS,GAAG;QACnB;IACF;IAEA,OAAO;QACL,IAAI,IAAI,CAAC,IAAI,EAAE;YACb,IAAI,CAAC,IAAI,CAAC,IAAI;YACd,IAAI,CAAC,IAAI,GAAG;YACZ,kIAAM,CAAC,IAAI,CAAC;QACd;IACF;IAEA,MAAM,SAAS;QACb,OAAO,IAAI,CAAC,OAAO;IACrB;AACF;AAOO,MAAM,iBAAiB,OAAO,sBAAsB,IAAI,IAAI;AAEnE,+DAA+D;AAC/D,wCAA4C;IAC1C,OAAO,sBAAsB,GAAG;AAClC"}},
    {"offset": {"line": 544, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/index.ts"],"sourcesContent":["/**\n * Centralized service initialization to ensure singleton pattern in Next.js\n */\nimport { jobManager } from './job-manager';\nimport { storageService } from './storage-service';\nimport { cleanupService } from './cleanup-service';\n\n// Initialize services on first import\nasync function initializeServices() {\n  try {\n    await storageService.initialize();\n    cleanupService.start();\n  } catch (error) {\n    console.error('Failed to initialize services:', error);\n  }\n}\n\n// Run initialization\ninitializeServices().catch(console.error);\n\nexport { jobManager, storageService, cleanupService };\n"],"names":[],"mappings":"AAAA;;CAEC;AACD;AACA;AACA;;;;;;;;AAEA,sCAAsC;AACtC,eAAe;IACb,IAAI;QACF,MAAM,yJAAc,CAAC,UAAU;QAC/B,yJAAc,CAAC,KAAK;IACtB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;IAClD;AACF;AAEA,qBAAqB;AACrB,qBAAqB,KAAK,CAAC,QAAQ,KAAK"}},
    {"offset": {"line": 580, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/image-processor.ts"],"sourcesContent":["import sharp from 'sharp';\nimport path from 'path';\nimport { promises as fs } from 'fs';\nimport { logger } from '../utils/logger';\n\ninterface FormatConfig {\n  quality?: number;\n  effort?: number;\n  mozjpeg?: boolean;\n  compressionLevel?: number;\n}\n\ninterface ResizeOptions {\n  width?: number;\n  height?: number;\n  fit?: string;\n}\n\ninterface ProcessSettings {\n  format: string;\n  quality?: number;\n  resize?: ResizeOptions;\n}\n\ninterface ProcessResult {\n  success: boolean;\n  originalSize?: number;\n  compressedSize?: number;\n  reduction?: number;\n  error?: string;\n}\n\nclass ImageProcessor {\n  private formatConfigs: Record<string, FormatConfig> = {\n    webp: {\n      quality: 80,\n      effort: 4\n    },\n    jpeg: {\n      quality: 80,\n      mozjpeg: true\n    },\n    png: {\n      compressionLevel: 9,\n      quality: 80\n    }\n  };\n\n  async processImage(inputPath: string, outputPath: string, settings: ProcessSettings): Promise<ProcessResult> {\n    try {\n      const { format, quality, resize } = settings;\n\n      // Get format config\n      const formatConfig: FormatConfig = { ...this.formatConfigs[format] };\n      if (quality !== undefined) {\n        formatConfig.quality = quality;\n      }\n\n      // Create sharp instance\n      let pipeline = sharp(inputPath);\n\n      // Apply resize if specified\n      if (resize && (resize.width || resize.height)) {\n        const resizeOptions: any = {\n          fit: resize.fit || 'inside',\n          withoutEnlargement: true\n        };\n        if (resize.width) resizeOptions.width = resize.width;\n        if (resize.height) resizeOptions.height = resize.height;\n        pipeline = pipeline.resize(resizeOptions);\n      }\n\n      // Convert to target format and save\n      await pipeline\n        .toFormat(format as any, formatConfig)\n        .toFile(outputPath);\n\n      // Get file sizes\n      const inputStats = await fs.stat(inputPath);\n      const outputStats = await fs.stat(outputPath);\n\n      logger.debug(`Processed: ${path.basename(inputPath)} -> ${path.basename(outputPath)}`);\n\n      return {\n        success: true,\n        originalSize: inputStats.size,\n        compressedSize: outputStats.size,\n        reduction: Math.round(((inputStats.size - outputStats.size) / inputStats.size) * 100)\n      };\n    } catch (error: any) {\n      logger.error(`Failed to process image ${inputPath}:`, error.message);\n      return {\n        success: false,\n        error: error.message\n      };\n    }\n  }\n\n  async processImages(\n    inputFiles: string[],\n    outputDir: string,\n    settings: ProcessSettings,\n    progressCallback?: (processed: number, total: number) => void\n  ) {\n    const results: any[] = [];\n    let processed = 0;\n\n    for (const inputFile of inputFiles) {\n      const filename = path.basename(inputFile);\n      const nameWithoutExt = path.parse(filename).name;\n      const outputFilename = `${nameWithoutExt}.${settings.format}`;\n      const outputPath = path.join(outputDir, outputFilename);\n\n      const result = await this.processImage(inputFile, outputPath, settings);\n\n      results.push({\n        filename,\n        outputFilename,\n        ...result\n      });\n\n      processed++;\n\n      if (progressCallback) {\n        progressCallback(processed, inputFiles.length);\n      }\n    }\n\n    const successful = results.filter(r => r.success).length;\n    const failed = results.filter(r => !r.success).length;\n    const totalOriginalSize = results.reduce((sum: number, r: any) => sum + (r.originalSize || 0), 0);\n    const totalCompressedSize = results.reduce((sum: number, r: any) => sum + (r.compressedSize || 0), 0);\n\n    logger.success(`Batch processing complete: ${successful} successful, ${failed} failed`);\n\n    return {\n      results,\n      summary: {\n        total: inputFiles.length,\n        successful,\n        failed,\n        totalOriginalSize,\n        totalCompressedSize,\n        totalReduction: totalOriginalSize > 0\n          ? Math.round(((totalOriginalSize - totalCompressedSize) / totalOriginalSize) * 100)\n          : 0\n      }\n    };\n  }\n\n  async validateImage(filePath: string) {\n    try {\n      const metadata = await sharp(filePath).metadata();\n      return {\n        valid: true,\n        format: metadata.format,\n        width: metadata.width,\n        height: metadata.height,\n        size: metadata.size\n      };\n    } catch (error: any) {\n      logger.warn(`Invalid image file: ${filePath}`, error.message);\n      return {\n        valid: false,\n        error: error.message\n      };\n    }\n  }\n\n  getSupportedFormats() {\n    return Object.keys(this.formatConfigs);\n  }\n}\n\nexport const imageProcessor = new ImageProcessor();\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AA6BA,MAAM;IACI,gBAA8C;QACpD,MAAM;YACJ,SAAS;YACT,QAAQ;QACV;QACA,MAAM;YACJ,SAAS;YACT,SAAS;QACX;QACA,KAAK;YACH,kBAAkB;YAClB,SAAS;QACX;IACF,EAAE;IAEF,MAAM,aAAa,SAAiB,EAAE,UAAkB,EAAE,QAAyB,EAA0B;QAC3G,IAAI;YACF,MAAM,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,GAAG;YAEpC,oBAAoB;YACpB,MAAM,eAA6B;gBAAE,GAAG,IAAI,CAAC,aAAa,CAAC,OAAO;YAAC;YACnE,IAAI,YAAY,WAAW;gBACzB,aAAa,OAAO,GAAG;YACzB;YAEA,wBAAwB;YACxB,IAAI,WAAW,IAAA,8GAAK,EAAC;YAErB,4BAA4B;YAC5B,IAAI,UAAU,CAAC,OAAO,KAAK,IAAI,OAAO,MAAM,GAAG;gBAC7C,MAAM,gBAAqB;oBACzB,KAAK,OAAO,GAAG,IAAI;oBACnB,oBAAoB;gBACtB;gBACA,IAAI,OAAO,KAAK,EAAE,cAAc,KAAK,GAAG,OAAO,KAAK;gBACpD,IAAI,OAAO,MAAM,EAAE,cAAc,MAAM,GAAG,OAAO,MAAM;gBACvD,WAAW,SAAS,MAAM,CAAC;YAC7B;YAEA,oCAAoC;YACpC,MAAM,SACH,QAAQ,CAAC,QAAe,cACxB,MAAM,CAAC;YAEV,iBAAiB;YACjB,MAAM,aAAa,MAAM,yGAAE,CAAC,IAAI,CAAC;YACjC,MAAM,cAAc,MAAM,yGAAE,CAAC,IAAI,CAAC;YAElC,kIAAM,CAAC,KAAK,CAAC,CAAC,WAAW,EAAE,4GAAI,CAAC,QAAQ,CAAC,WAAW,IAAI,EAAE,4GAAI,CAAC,QAAQ,CAAC,aAAa;YAErF,OAAO;gBACL,SAAS;gBACT,cAAc,WAAW,IAAI;gBAC7B,gBAAgB,YAAY,IAAI;gBAChC,WAAW,KAAK,KAAK,CAAC,AAAC,CAAC,WAAW,IAAI,GAAG,YAAY,IAAI,IAAI,WAAW,IAAI,GAAI;YACnF;QACF,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,wBAAwB,EAAE,UAAU,CAAC,CAAC,EAAE,MAAM,OAAO;YACnE,OAAO;gBACL,SAAS;gBACT,OAAO,MAAM,OAAO;YACtB;QACF;IACF;IAEA,MAAM,cACJ,UAAoB,EACpB,SAAiB,EACjB,QAAyB,EACzB,gBAA6D,EAC7D;QACA,MAAM,UAAiB,EAAE;QACzB,IAAI,YAAY;QAEhB,KAAK,MAAM,aAAa,WAAY;YAClC,MAAM,WAAW,4GAAI,CAAC,QAAQ,CAAC;YAC/B,MAAM,iBAAiB,4GAAI,CAAC,KAAK,CAAC,UAAU,IAAI;YAChD,MAAM,iBAAiB,GAAG,eAAe,CAAC,EAAE,SAAS,MAAM,EAAE;YAC7D,MAAM,aAAa,4GAAI,CAAC,IAAI,CAAC,WAAW;YAExC,MAAM,SAAS,MAAM,IAAI,CAAC,YAAY,CAAC,WAAW,YAAY;YAE9D,QAAQ,IAAI,CAAC;gBACX;gBACA;gBACA,GAAG,MAAM;YACX;YAEA;YAEA,IAAI,kBAAkB;gBACpB,iBAAiB,WAAW,WAAW,MAAM;YAC/C;QACF;QAEA,MAAM,aAAa,QAAQ,MAAM,CAAC,CAAA,IAAK,EAAE,OAAO,EAAE,MAAM;QACxD,MAAM,SAAS,QAAQ,MAAM,CAAC,CAAA,IAAK,CAAC,EAAE,OAAO,EAAE,MAAM;QACrD,MAAM,oBAAoB,QAAQ,MAAM,CAAC,CAAC,KAAa,IAAW,MAAM,CAAC,EAAE,YAAY,IAAI,CAAC,GAAG;QAC/F,MAAM,sBAAsB,QAAQ,MAAM,CAAC,CAAC,KAAa,IAAW,MAAM,CAAC,EAAE,cAAc,IAAI,CAAC,GAAG;QAEnG,kIAAM,CAAC,OAAO,CAAC,CAAC,2BAA2B,EAAE,WAAW,aAAa,EAAE,OAAO,OAAO,CAAC;QAEtF,OAAO;YACL;YACA,SAAS;gBACP,OAAO,WAAW,MAAM;gBACxB;gBACA;gBACA;gBACA;gBACA,gBAAgB,oBAAoB,IAChC,KAAK,KAAK,CAAC,AAAC,CAAC,oBAAoB,mBAAmB,IAAI,oBAAqB,OAC7E;YACN;QACF;IACF;IAEA,MAAM,cAAc,QAAgB,EAAE;QACpC,IAAI;YACF,MAAM,WAAW,MAAM,IAAA,8GAAK,EAAC,UAAU,QAAQ;YAC/C,OAAO;gBACL,OAAO;gBACP,QAAQ,SAAS,MAAM;gBACvB,OAAO,SAAS,KAAK;gBACrB,QAAQ,SAAS,MAAM;gBACvB,MAAM,SAAS,IAAI;YACrB;QACF,EAAE,OAAO,OAAY;YACnB,kIAAM,CAAC,IAAI,CAAC,CAAC,oBAAoB,EAAE,UAAU,EAAE,MAAM,OAAO;YAC5D,OAAO;gBACL,OAAO;gBACP,OAAO,MAAM,OAAO;YACtB;QACF;IACF;IAEA,sBAAsB;QACpB,OAAO,OAAO,IAAI,CAAC,IAAI,CAAC,aAAa;IACvC;AACF;AAEO,MAAM,iBAAiB,IAAI"}},
    {"offset": {"line": 796, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/services/zip-service.ts"],"sourcesContent":["import archiver from 'archiver';\nimport fs from 'fs';\nimport path from 'path';\nimport { logger } from '../utils/logger';\n\ninterface FileEntry {\n  filePath: string;\n  name?: string;\n}\n\nclass ZipService {\n  async createZip(sourceDir: string, outputPath: string) {\n    return new Promise((resolve, reject) => {\n      const output = fs.createWriteStream(outputPath);\n      const archive = archiver('zip', {\n        zlib: { level: 9 } // Maximum compression\n      });\n\n      output.on('close', () => {\n        const sizeInMB = (archive.pointer() / 1024 / 1024).toFixed(2);\n        logger.info(`ZIP created: ${outputPath} (${sizeInMB} MB)`);\n        resolve({\n          success: true,\n          path: outputPath,\n          size: archive.pointer()\n        });\n      });\n\n      output.on('error', (error) => {\n        logger.error('ZIP output stream error:', error);\n        reject(error);\n      });\n\n      archive.on('error', (error) => {\n        logger.error('ZIP archive error:', error);\n        reject(error);\n      });\n\n      archive.on('warning', (warning: any) => {\n        if (warning.code === 'ENOENT') {\n          logger.warn('ZIP warning:', warning);\n        } else {\n          reject(warning);\n        }\n      });\n\n      archive.pipe(output);\n      archive.directory(sourceDir, false);\n      archive.finalize();\n    });\n  }\n\n  async createZipFromFiles(files: FileEntry[], outputPath: string) {\n    return new Promise((resolve, reject) => {\n      const output = fs.createWriteStream(outputPath);\n      const archive = archiver('zip', {\n        zlib: { level: 9 }\n      });\n\n      output.on('close', () => {\n        logger.info(`ZIP created from ${files.length} files`);\n        resolve({\n          success: true,\n          path: outputPath,\n          size: archive.pointer()\n        });\n      });\n\n      output.on('error', reject);\n      archive.on('error', reject);\n\n      archive.pipe(output);\n\n      files.forEach(({ filePath, name }) => {\n        archive.file(filePath, { name: name || path.basename(filePath) });\n      });\n\n      archive.finalize();\n    });\n  }\n}\n\nexport const zipService = new ZipService();\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAOA,MAAM;IACJ,MAAM,UAAU,SAAiB,EAAE,UAAkB,EAAE;QACrD,OAAO,IAAI,QAAQ,CAAC,SAAS;YAC3B,MAAM,SAAS,wGAAE,CAAC,iBAAiB,CAAC;YACpC,MAAM,UAAU,IAAA,8IAAQ,EAAC,OAAO;gBAC9B,MAAM;oBAAE,OAAO;gBAAE,EAAE,sBAAsB;YAC3C;YAEA,OAAO,EAAE,CAAC,SAAS;gBACjB,MAAM,WAAW,CAAC,QAAQ,OAAO,KAAK,OAAO,IAAI,EAAE,OAAO,CAAC;gBAC3D,kIAAM,CAAC,IAAI,CAAC,CAAC,aAAa,EAAE,WAAW,EAAE,EAAE,SAAS,IAAI,CAAC;gBACzD,QAAQ;oBACN,SAAS;oBACT,MAAM;oBACN,MAAM,QAAQ,OAAO;gBACvB;YACF;YAEA,OAAO,EAAE,CAAC,SAAS,CAAC;gBAClB,kIAAM,CAAC,KAAK,CAAC,4BAA4B;gBACzC,OAAO;YACT;YAEA,QAAQ,EAAE,CAAC,SAAS,CAAC;gBACnB,kIAAM,CAAC,KAAK,CAAC,sBAAsB;gBACnC,OAAO;YACT;YAEA,QAAQ,EAAE,CAAC,WAAW,CAAC;gBACrB,IAAI,QAAQ,IAAI,KAAK,UAAU;oBAC7B,kIAAM,CAAC,IAAI,CAAC,gBAAgB;gBAC9B,OAAO;oBACL,OAAO;gBACT;YACF;YAEA,QAAQ,IAAI,CAAC;YACb,QAAQ,SAAS,CAAC,WAAW;YAC7B,QAAQ,QAAQ;QAClB;IACF;IAEA,MAAM,mBAAmB,KAAkB,EAAE,UAAkB,EAAE;QAC/D,OAAO,IAAI,QAAQ,CAAC,SAAS;YAC3B,MAAM,SAAS,wGAAE,CAAC,iBAAiB,CAAC;YACpC,MAAM,UAAU,IAAA,8IAAQ,EAAC,OAAO;gBAC9B,MAAM;oBAAE,OAAO;gBAAE;YACnB;YAEA,OAAO,EAAE,CAAC,SAAS;gBACjB,kIAAM,CAAC,IAAI,CAAC,CAAC,iBAAiB,EAAE,MAAM,MAAM,CAAC,MAAM,CAAC;gBACpD,QAAQ;oBACN,SAAS;oBACT,MAAM;oBACN,MAAM,QAAQ,OAAO;gBACvB;YACF;YAEA,OAAO,EAAE,CAAC,SAAS;YACnB,QAAQ,EAAE,CAAC,SAAS;YAEpB,QAAQ,IAAI,CAAC;YAEb,MAAM,OAAO,CAAC,CAAC,EAAE,QAAQ,EAAE,IAAI,EAAE;gBAC/B,QAAQ,IAAI,CAAC,UAAU;oBAAE,MAAM,QAAQ,4GAAI,CAAC,QAAQ,CAAC;gBAAU;YACjE;YAEA,QAAQ,QAAQ;QAClB;IACF;AACF;AAEO,MAAM,aAAa,IAAI"}},
    {"offset": {"line": 879, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/lib/utils/errors.ts"],"sourcesContent":["export class AppError extends Error {\n  constructor(\n    message: string,\n    public statusCode: number = 500,\n    public details: any = {}\n  ) {\n    super(message);\n    this.name = this.constructor.name;\n    Error.captureStackTrace(this, this.constructor);\n  }\n}\n\nexport class ValidationError extends AppError {\n  constructor(message: string, details: any = {}) {\n    super(message, 400, details);\n  }\n}\n\nexport class NotFoundError extends AppError {\n  constructor(resource: string = 'Resource') {\n    super(`${resource} not found`, 404);\n  }\n}\n\nexport class ConflictError extends AppError {\n  constructor(message: string) {\n    super(message, 409);\n  }\n}\n\nexport class BadRequestError extends AppError {\n  constructor(message: string) {\n    super(message, 400);\n  }\n}\n\nexport class InternalServerError extends AppError {\n  constructor(message: string = 'Internal server error') {\n    super(message, 500);\n  }\n}\n\nexport class ProcessingError extends AppError {\n  constructor(message: string) {\n    super(message, 500);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;AAAO,MAAM,iBAAiB;;;IAC5B,YACE,OAAe,EACf,AAAO,aAAqB,GAAG,EAC/B,AAAO,UAAe,CAAC,CAAC,CACxB;QACA,KAAK,CAAC,eAHC,aAAA,iBACA,UAAA;QAGP,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,WAAW,CAAC,IAAI;QACjC,MAAM,iBAAiB,CAAC,IAAI,EAAE,IAAI,CAAC,WAAW;IAChD;AACF;AAEO,MAAM,wBAAwB;IACnC,YAAY,OAAe,EAAE,UAAe,CAAC,CAAC,CAAE;QAC9C,KAAK,CAAC,SAAS,KAAK;IACtB;AACF;AAEO,MAAM,sBAAsB;IACjC,YAAY,WAAmB,UAAU,CAAE;QACzC,KAAK,CAAC,GAAG,SAAS,UAAU,CAAC,EAAE;IACjC;AACF;AAEO,MAAM,sBAAsB;IACjC,YAAY,OAAe,CAAE;QAC3B,KAAK,CAAC,SAAS;IACjB;AACF;AAEO,MAAM,wBAAwB;IACnC,YAAY,OAAe,CAAE;QAC3B,KAAK,CAAC,SAAS;IACjB;AACF;AAEO,MAAM,4BAA4B;IACvC,YAAY,UAAkB,uBAAuB,CAAE;QACrD,KAAK,CAAC,SAAS;IACjB;AACF;AAEO,MAAM,wBAAwB;IACnC,YAAY,OAAe,CAAE;QAC3B,KAAK,CAAC,SAAS;IACjB;AACF"}},
    {"offset": {"line": 940, "column": 0}, "map": {"version":3,"sources":["file:///home/strykerux/aurora33.dev/redux/app/api/jobs/%5BjobId%5D/process/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport path from 'path';\nimport { promises as fs } from 'fs';\nimport { jobManager, storageService } from '@/lib/services';\nimport { imageProcessor } from '@/lib/services/image-processor';\nimport { zipService } from '@/lib/services/zip-service';\nimport { config } from '@/lib/config';\nimport { NotFoundError, BadRequestError } from '@/lib/utils/errors';\nimport { logger } from '@/lib/utils/logger';\n\ninterface ProcessRequest {\n  format: string;\n  quality?: number;\n  resize?: {\n    width?: number;\n    height?: number;\n    fit?: string;\n  };\n}\n\n/**\n * POST /api/jobs/:jobId/process\n * Start compression processing for uploaded images\n */\nexport async function POST(\n  request: NextRequest,\n  { params }: { params: Promise<{ jobId: string }> }\n) {\n  try {\n    const { jobId } = await params;\n    const job = jobManager.getJob(jobId);\n\n    if (!job) {\n      throw new NotFoundError('Job');\n    }\n\n    if (job.status !== 'uploaded') {\n      throw new BadRequestError(`Cannot process job in status: ${job.status}`);\n    }\n\n    const body: ProcessRequest = await request.json();\n\n    // Validate format\n    if (!config.outputFormats.includes(body.format)) {\n      throw new BadRequestError(\n        `Invalid format. Allowed: ${config.outputFormats.join(', ')}`\n      );\n    }\n\n    // Set job settings and status\n    jobManager.setJobSettings(jobId, { format: body.format, quality: body.quality, resize: body.resize });\n    jobManager.setJobStatus(jobId, 'processing');\n\n    logger.info(`Starting processing for job: ${jobId}`);\n\n    // Get input and output directories\n    const uploadDir = storageService.getUploadDir(jobId);\n    const processedDir = storageService.getProcessedDir(jobId);\n\n    // Get list of uploaded files\n    const files = await storageService.listFiles(uploadDir);\n    const inputPaths = files.map(f => path.join(uploadDir, f));\n\n    // Process images asynchronously (non-blocking)\n    setImmediate(async () => {\n      try {\n        const result = await imageProcessor.processImages(\n          inputPaths,\n          processedDir,\n          {\n            format: body.format,\n            quality: body.quality,\n            resize: body.resize\n          },\n          (processed, total) => {\n            jobManager.updateProgress(jobId, processed, total);\n          }\n        );\n\n        // Update job with results\n        let successCount = 0;\n        for (const fileResult of result.results) {\n          if (fileResult.success) {\n            jobManager.addProcessedFile(\n              jobId,\n              fileResult.outputFilename,\n              fileResult.originalSize,\n              fileResult.compressedSize\n            );\n            successCount++;\n          }\n        }\n\n        // Create ZIP file\n        const zipPath = path.join(storageService.getJobDir(jobId), 'processed.zip');\n        await zipService.createZip(processedDir, zipPath);\n\n        jobManager.setJobStatus(jobId, 'completed');\n        logger.success(\n          `Job ${jobId} completed: ${successCount}/${result.results.length} files processed`\n        );\n      } catch (error: any) {\n        logger.error(`Job ${jobId} processing failed:`, error.message);\n        jobManager.setJobStatus(jobId, 'failed', error.message);\n      }\n    });\n\n    return NextResponse.json({\n      success: true,\n      message: 'Processing started',\n      jobId\n    });\n  } catch (error: any) {\n    const statusCode = error.statusCode || 500;\n    logger.error('Process error:', error.message);\n    return NextResponse.json(\n      { success: false, error: error.message },\n      { status: statusCode }\n    );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AAEA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AAgBO,eAAe,KACpB,OAAoB,EACpB,EAAE,MAAM,EAA0C;IAElD,IAAI;QACF,MAAM,EAAE,KAAK,EAAE,GAAG,MAAM;QACxB,MAAM,MAAM,iJAAU,CAAC,MAAM,CAAC;QAE9B,IAAI,CAAC,KAAK;YACR,MAAM,IAAI,yIAAa,CAAC;QAC1B;QAEA,IAAI,IAAI,MAAM,KAAK,YAAY;YAC7B,MAAM,IAAI,2IAAe,CAAC,CAAC,8BAA8B,EAAE,IAAI,MAAM,EAAE;QACzE;QAEA,MAAM,OAAuB,MAAM,QAAQ,IAAI;QAE/C,kBAAkB;QAClB,IAAI,CAAC,yHAAM,CAAC,aAAa,CAAC,QAAQ,CAAC,KAAK,MAAM,GAAG;YAC/C,MAAM,IAAI,2IAAe,CACvB,CAAC,yBAAyB,EAAE,yHAAM,CAAC,aAAa,CAAC,IAAI,CAAC,OAAO;QAEjE;QAEA,8BAA8B;QAC9B,iJAAU,CAAC,cAAc,CAAC,OAAO;YAAE,QAAQ,KAAK,MAAM;YAAE,SAAS,KAAK,OAAO;YAAE,QAAQ,KAAK,MAAM;QAAC;QACnG,iJAAU,CAAC,YAAY,CAAC,OAAO;QAE/B,kIAAM,CAAC,IAAI,CAAC,CAAC,6BAA6B,EAAE,OAAO;QAEnD,mCAAmC;QACnC,MAAM,YAAY,yJAAc,CAAC,YAAY,CAAC;QAC9C,MAAM,eAAe,yJAAc,CAAC,eAAe,CAAC;QAEpD,6BAA6B;QAC7B,MAAM,QAAQ,MAAM,yJAAc,CAAC,SAAS,CAAC;QAC7C,MAAM,aAAa,MAAM,GAAG,CAAC,CAAA,IAAK,4GAAI,CAAC,IAAI,CAAC,WAAW;QAEvD,+CAA+C;QAC/C,aAAa;YACX,IAAI;gBACF,MAAM,SAAS,MAAM,yJAAc,CAAC,aAAa,CAC/C,YACA,cACA;oBACE,QAAQ,KAAK,MAAM;oBACnB,SAAS,KAAK,OAAO;oBACrB,QAAQ,KAAK,MAAM;gBACrB,GACA,CAAC,WAAW;oBACV,iJAAU,CAAC,cAAc,CAAC,OAAO,WAAW;gBAC9C;gBAGF,0BAA0B;gBAC1B,IAAI,eAAe;gBACnB,KAAK,MAAM,cAAc,OAAO,OAAO,CAAE;oBACvC,IAAI,WAAW,OAAO,EAAE;wBACtB,iJAAU,CAAC,gBAAgB,CACzB,OACA,WAAW,cAAc,EACzB,WAAW,YAAY,EACvB,WAAW,cAAc;wBAE3B;oBACF;gBACF;gBAEA,kBAAkB;gBAClB,MAAM,UAAU,4GAAI,CAAC,IAAI,CAAC,yJAAc,CAAC,SAAS,CAAC,QAAQ;gBAC3D,MAAM,iJAAU,CAAC,SAAS,CAAC,cAAc;gBAEzC,iJAAU,CAAC,YAAY,CAAC,OAAO;gBAC/B,kIAAM,CAAC,OAAO,CACZ,CAAC,IAAI,EAAE,MAAM,YAAY,EAAE,aAAa,CAAC,EAAE,OAAO,OAAO,CAAC,MAAM,CAAC,gBAAgB,CAAC;YAEtF,EAAE,OAAO,OAAY;gBACnB,kIAAM,CAAC,KAAK,CAAC,CAAC,IAAI,EAAE,MAAM,mBAAmB,CAAC,EAAE,MAAM,OAAO;gBAC7D,iJAAU,CAAC,YAAY,CAAC,OAAO,UAAU,MAAM,OAAO;YACxD;QACF;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS;YACT;QACF;IACF,EAAE,OAAO,OAAY;QACnB,MAAM,aAAa,MAAM,UAAU,IAAI;QACvC,kIAAM,CAAC,KAAK,CAAC,kBAAkB,MAAM,OAAO;QAC5C,OAAO,gJAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO,MAAM,OAAO;QAAC,GACvC;YAAE,QAAQ;QAAW;IAEzB;AACF"}}]
}